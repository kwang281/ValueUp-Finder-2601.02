# Q&A: Streamlit Cloud 운영 이슈 분석

## Q1. 수집된 데이터는 어디에 저장되나요?
현재 코드는 데이터를 `data/` 폴더 내의 `.json` 파일로 저장합니다. (`save_daily_cache` 함수 참조)
- **로컬 실행 시**: 내 컴퓨터의 하드디스크에 영구적으로 저장됩니다.
- **Streamlit Cloud 실행 시**: 클라우드가 제공하는 **임시 저장공간(Container)** 에 저장됩니다.
    - 🚨 **중요**: 이 공간은 **휘발성(Ephemeral)** 입니다. 앱이 다시 시작되거나, 일정 시간 사용하지 않아 "Sleep Mode"에 들어갔다 깨어나면 **모든 파일이 초기화(삭제)됩니다.**

## Q2. 업데이트 시간(16:00)마다 문제가 생기는 이유는?
가장 유력한 원인은 **데이터 소실 후 재수집 실패**입니다.
1.  앱이 재시작되면서 기존에 저장해둔 `company_data_*.json` 파일이 사라집니다.
2.  코드는 파일이 없으니 **300개 기업에 대한 웹 크롤링(FnGuide)** 을 다시 시도합니다. (`fetch_real_dashboard_data`)
3.  **문제 발생**:
    - Streamlit Cloud 서버는 성능(CPU/RAM)이 제한적입니다. 300번의 연속된 요청은 **타임아웃(Timeout)** 에 걸리거나 메모리 부족으로 프로세스(Worker)가 죽을 수 있습니다.
    - 또는, 짧은 시간 내 과도한 요청으로 인해 외부 사이트(FnGuide)에서 **차단(Blocking)** 당했을 수 있습니다.

## Q3. Sleep Mode 대책은?
Streamlit Cloud(무료 티어)는 방문자가 없으면 서버 자원을 아끼기 위해 앱을 **재워버립니다(Sleep).**
- **앱 자체 해결 불가**: Streamlit Cloud 무료 버전에서는 Sleep Mode를 끌 수 없습니다. 또한 앱이 깨어날 때마다 데이터를 처음부터 다시 수집해야 하므로 매우 느리고 불안정합니다.

---

## ✅ 권장 해결 솔루션: "Git Scraping" (데이터 수집 분리)
앱이 직접 크롤링을 하는 것이 아니라, **GitHub Actions가 주기적으로 데이터를 수집해서 Git 저장소에 파일로 저장해두는 방식**입니다.

### 왜 이 방식이 좋은가요?
1.  **영구 저장**: 수집된 데이터가 `company_data.json` 파일로 GitHub 저장소에 커밋(저장)되므로, 앱이 재시작되어도 데이터가 사라지지 않습니다.
2.  **안정성**: 사용자가 접속할 때 크롤링을 하는 게 아니라, 미리 새벽에 수집해둔 파일을 **읽기만 하면 되므로 0.1초 만에 로딩**됩니다.
3.  **Sleep 무관**: 앱이 잠들어도 상관없습니다. 데이터는 GitHub에 안전하게 보관되어 있습니다.

### 구현 방법
다시 **GitHub Actions (`.github/workflows/daily_scraping.yml`)** 를 생성하여, 매일 16:00에 스크립트를 실행하고 결과를 `commit` 하도록 설정해야 합니다. (앞서 삭제하신 기능과는 목적이 다릅니다.)
